## ğŸ§  Task B - Face Matching (Multi-Class Recognition with Distorted Inputs)

This project implements a **face verification system** that can match distorted or altered face images to their correct identities. Unlike classification, this task focuses on **verifying whether two face images belong to the same person**, even under challenging conditions.

---

## ğŸ“ Dataset Structure

The dataset is organized as follows:

```
dataset/
â”œâ”€â”€ 001_frontal/
â”‚   â”œâ”€â”€ clean1.jpg
â”‚   â”œâ”€â”€ clean2.jpg
â”‚   â””â”€â”€ distortion/
â”‚       â”œâ”€â”€ distorted1.jpg
â”‚       â””â”€â”€ distorted2.jpg
â”œâ”€â”€ 002_frontal/
â”‚   â”œâ”€â”€ ...
...
```

* Each identity (e.g., `001_frontal/`) contains clean reference images.
* Distorted versions are inside a nested `distortion/` subfolder.

---

## ğŸ¯ Objective

Build a **generalizable face embedding model** that:

* Brings similar (same identity) images close in embedding space.
* Pushes different identities far apart.
* Correctly verifies whether a distorted face belongs to a reference identity.

---

## ğŸ› ï¸ Project Structure

```
.
â”œâ”€â”€ config.py                # All training & path configs
â”œâ”€â”€ train.py                 # Main training script
â”œâ”€â”€ evaluate.py              # Computes Top-1 Accuracy & Macro F1
â”œâ”€â”€ test.py                  # Command-line script to test custom input
â”œâ”€â”€ siamese_model.py         # Siamese network & backbone model
â”œâ”€â”€ utils.py                 # Embedding functions, contrastive loss, image loader
â”œâ”€â”€ data_loader.py           # Dataset loader for face pairs
```

---

## ğŸ—ï¸ Model Architecture

* **Backbone**: ResNet18 (ImageNet pretrained)
* **Network**: Siamese Network

  * Takes two images and compares embeddings
* **Loss**: Contrastive Loss
* **Metric**: Euclidean Distance

---

## âš™ï¸ Configuration (`config.py`)

```python
# Paths
TRAIN_DIR = "Task_B/train"
VAL_DIR = "Task_B/val"
MODEL_SAVE_PATH = "model/best_identity_model.pth"

# Image settings
IMG_SIZE = (224, 224)

# Training settings
EPOCHS = 5
BATCH_SIZE = 32
LEARNING_RATE = 1e-4
MARGIN = 1.0  # for contrastive loss

# Inference
THRESHOLD = 0.375  # Distance threshold for verification
DEVICE = "cuda"  # or "cpu"
```

---

## ğŸš€ Training

```bash
python train.py
```

* Trains using contrastive loss
* Shows **training accuracy live** using `tqdm`
* Saves the best model (`best_identity_model.pth`)
* Saves `accuracy_history.pt` and `f1_history.pt` for plotting

---

## ğŸ“Š Evaluation

```bash
python evaluate.py
```

* Compares distorted images to reference identities
* Outputs:

  * âœ… **Top-1 Accuracy**
  * âœ… **Macro-averaged F1 Score**
* Uses binary (0/1) match result for metric calculation

---

## ğŸ§ª Test on Custom Folder

```bash
python test.py path/to/distorted_images/
```

* Runs face matching on custom folder of distorted images
* Outputs matched identity or "no match" in console

---

## ğŸ§  How Matching Works

1. **Embedding Generation**:

   * Both test and reference images are passed through the same embedding model.
2. **Distance Calculation**:

   * Uses Euclidean distance between embeddings.
3. **Thresholding**:

   * If distance < `THRESHOLD`, itâ€™s a match.

---

## âœ… Evaluation Metrics

| Metric         | Value  |
| -------------- | ------ |
| Top-1 Accuracy | 0.8693 |
| Macro F1-Score | 0.8047 |

---

## ğŸ Future Improvements

* Use Triplet Loss or ArcFace for more robust embeddings.
* Add Face Alignment or MTCNN for preprocessing.
* Use ONNX or TorchScript for deployment.

---

## ğŸ™Œ Acknowledgements

* Based on ideas from [FaceNet](https://arxiv.org/abs/1503.03832) and Siamese Networks
* Pretrained models via `torchvision.models`

---